{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Note!!!!\n",
        "\n",
        "We have used two types of model for the same purpuse (text generation)\n",
        "\n",
        "1 DialoGPT: from microsoft for dialogue wise text generation\n",
        "\n",
        "2 GPT3: from OpenAI for detailed informations"
      ],
      "metadata": {
        "id": "T8LAeqkIS1r9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation (Conversation wise DialoGPT)"
      ],
      "metadata": {
        "id": "QWB2Tnn1MVAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"microsoft/DialoGPT-medium\"  # You can use \"microsoft/DialoGPT-small\", \"microsoft/DialoGPT-large\", etc.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "ZQtnj5jsQyFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(input_text, max_length=1000, num_return_sequences=1):\n",
        "    # Encode the input text\n",
        "    input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # Generate response\n",
        "    outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=num_return_sequences,\n",
        "                             pad_token_id=tokenizer.eos_token_id, no_repeat_ngram_size=3, top_p=0.92, temperature=0.75)\n",
        "\n",
        "    # Decode the generated response\n",
        "    generated_responses = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "    return generated_responses"
      ],
      "metadata": {
        "id": "wDl6wX3_F2Y_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text\n",
        "input_text = \"Who is Virat Kohli?\"\n",
        "\n",
        "# Generate response\n",
        "generated_responses = generate_response(input_text)\n",
        "\n",
        "# Display the generated response\n",
        "for i, response in enumerate(generated_responses):\n",
        "    print(f\"Generated Response {i+1}:\\n{response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qg7Fb4yMRW8",
        "outputId": "cf35e5d9-ab76-4a95-8ea0-3f36aaaa0dea"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response 1:\n",
            "Who is Virat Kohli?He's a cricket player.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text\n",
        "input_text = \"How are you?\"\n",
        "\n",
        "# Generate response\n",
        "generated_responses = generate_response(input_text)\n",
        "\n",
        "# Display the generated response\n",
        "for i, response in enumerate(generated_responses):\n",
        "    print(f\"Generated Response {i+1}:\\n{response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZAiPxfoMRZ8",
        "outputId": "436e17c7-858f-4925-e00d-865f4776a802"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response 1:\n",
            "How are you?I'm good, how are you?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text\n",
        "input_text = \"what is mango?\"\n",
        "\n",
        "# Generate response\n",
        "generated_responses = generate_response(input_text)\n",
        "\n",
        "# Display the generated response\n",
        "for i, response in enumerate(generated_responses):\n",
        "    print(f\"Generated Response {i+1}:\\n{response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmmAM5HiMRdp",
        "outputId": "e3d5c5be-30d7-4601-96e7-630050a2a03b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response 1:\n",
            "what is mango?A fruit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation (Detailed Wise GPT3)"
      ],
      "metadata": {
        "id": "0Vd3ZR0ePCLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"gpt2-large\"  # You can use \"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "pQtofCngQL_i"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length=1000, num_return_sequences=1):\n",
        "    # Encode the input text\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate response\n",
        "    outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=num_return_sequences,\n",
        "                             pad_token_id=tokenizer.eos_token_id, no_repeat_ngram_size=2, top_p=0.92, temperature=0.85)\n",
        "\n",
        "    # Decode the generated response\n",
        "    generated_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "    return generated_texts"
      ],
      "metadata": {
        "id": "DxkxYPO3Ogec"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input prompt\n",
        "prompt = \"Write a detailed note on agriculture.\"\n",
        "\n",
        "# Generate text\n",
        "generated_texts = generate_text(prompt)\n",
        "\n",
        "# Display the generated text\n",
        "for i, text in enumerate(generated_texts):\n",
        "    print(f\"Generated Text {i+1}:\\n{text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQsFFuhaPPc3",
        "outputId": "432879c1-51d0-492d-cca0-76ba5f5d93ff"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 1:\n",
            "Write a detailed note on agriculture.\n",
            "\n",
            "The first step is to write a note about agriculture, which is a very important topic for the farmers. It is important to know the basic facts about the farming industry, such as the number of farmers, the type of farming, and the types of crops. The farmers should also know about their rights and responsibilities. They should know how to get the necessary permits and licenses. This is the first thing that the farmer should do. He should write down the information about his farm. Then he should go to the local government office and get a permit. After that, he can start farming. If he has a small farm, it is very easy to start. But if he is in a big farm or a large farm with many acres, then it will be very difficult. You should get permission from the government before you start to farm and you should have a license. In the beginning, you will have to pay a fee for your permit and license, but after that you can farm without any problems. Once you have the permit, there is no need to worry about it. There are many farmers who have been farming for many years and they have never had any problem. So, if you are a farmer, don't worry. Just go ahead and start your farm!\n",
            "...\n",
            "In the next step, we will discuss the other important topics that are important for farmers:\n",
            "1. How to prepare for a harvest. 2. What to do if the harvest is not good. 3. When to plant. 4. Which crops to grow. 5. Why to use pesticides. 6. Where to buy seeds. 7. Who to sell your seeds to. 8. Should you use a tractor or an irrigation system. 9. Can you grow vegetables on your land? 10. Do you need a water tank? 11. Is it necessary to have an electric water pump? 12. Are there any other types? 13. Will you be able to water your crops? 14. Does your soil need fertilizer? 15. Have you ever had a problem with your crop? 16. Did you know that there are different types and types are not always the same? 17. Was there a time when you had to go back to your home to collect your harvest? 18. Were you able or not to harvest your own crop. 19. Has your family ever been in trouble with the police? 20. Would you like to be a police officer? 21. Could you tell us about your life before becoming a policeman? 22. Tell us what you do for work. 23. Describe your job. 24. Give us some examples of your work and how you get along with other people. 25. Explain what your day is like. 26. Write down some of the things that make you happy. 27. List some things you don´t like about life. 28. Talk about some other things. 29. Share some stories. 30. Ask us to tell you about our lives. 31. We will tell about you. 32. Don´T forget to ask us questions. 33. Be patient. 34. Remember that we are here to help you and to give you advice. 35. Let´s start!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input prompt\n",
        "prompt = \"Guide me, how to start learning Machine Learning?\"\n",
        "\n",
        "# Generate text\n",
        "generated_texts = generate_text(prompt)\n",
        "\n",
        "# Display the generated text\n",
        "for i, text in enumerate(generated_texts):\n",
        "    print(f\"Generated Text {i+1}:\\n{text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JvXFN43PQTU",
        "outputId": "880f6c0e-be7f-4c63-fea6-ad9e90b83719"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text 1:\n",
            "Guide me, how to start learning Machine Learning?\n",
            "\n",
            "I'm a big fan of the book \"Machine Learning: The Art and Science of Computer Learning\" by Geoffrey Hinton. It's a great book and I highly recommend it.\n",
            "The book is a good introduction to Machine learning and it's also a very good book to read if you want to learn more about Machine Intelligence. I've also found that the books \"The Art of Machine Translation\" and \"How to Learn Machine Language\" are also good books to get started with Machine intelligence.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vpe5oA7GReo7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}